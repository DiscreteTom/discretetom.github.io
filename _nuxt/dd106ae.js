(window.webpackJsonp=window.webpackJsonp||[]).push([[109,417],{1347:function(t,n,e){const r={render:function(){var t=this;t.$createElement;return t._self._c,t._m(0)},staticRenderFns:[function(){var t=this,n=t.$createElement,r=t._self._c||n;return r("div",{staticClass:"frontmatter-markdown"},[r("p",[t._v("本文是观看"),r("a",{attrs:{href:"https://www.bilibili.com/video/BV1zu4y1Z7mc/"}},[t._v("此视频")]),t._v("的笔记")]),t._v(" "),r("h2",{attrs:{id:"langchain"}},[t._v("LangChain")]),t._v(" "),r("ul",[r("li",[t._v("一个编程框架，提供 Python/Javascript/Typescript SDK")]),t._v(" "),r("li",[t._v("用来工程化、简化基于 LLM 的应用的开发")]),t._v(" "),r("li",[t._v("把和 LLM 的交互抽象为一系列的 Chain")]),t._v(" "),r("li",[t._v("通过设置"),r("code",{pre:!0},[t._v("langchain.debug = True")]),t._v("可以查看每个步骤发生了什么")])]),t._v(" "),r("h2",{attrs:{id:"模块"}},[t._v("模块")]),t._v(" "),r("h3",{attrs:{id:"llm"}},[t._v("LLM")]),t._v(" "),r("p",[t._v("略，就是各种大语言模型")]),t._v(" "),r("h3",{attrs:{id:"prompt"}},[t._v("Prompt")]),t._v(" "),r("p",[t._v("为了实现提示词的复用，LangChain 通常不会直接使用 prompt，而是使用 prompt template，并在 template 中预留参数的 slot")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("prompts "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ChatPromptTemplate\n\ntemplate_string "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""Translate the text \\\nthat is delimited by triple backticks \\\ninto a style that is {style}. \\\ntext: ```{text}```\n"""')]),t._v("\n\nprompt_template "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ChatPromptTemplate"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_template"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("template_string"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprompt_template"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("format_messages"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("style"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v("'xxx'")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" text"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v("'xxx'")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),r("p",[t._v("在以上示例中，"),r("code",{pre:!0},[t._v("{style}")]),t._v(" 和 "),r("code",{pre:!0},[t._v("{text}")]),t._v(" 就是 slot。"),r("code",{pre:!0},[t._v("ChatPromptTemplate")]),t._v("会识别字符串中的这些 slot，并在"),r("code",{pre:!0},[t._v("format_messages")]),t._v("的时候填充 slot")]),t._v(" "),r("h3",{attrs:{id:"output-parser"}},[t._v("Output Parser")]),t._v(" "),r("p",[t._v("如果我们希望 LLM 返回的结果是结构化的，那么我们需要定义一个"),r("code",{pre:!0},[t._v("OutputParser")]),t._v("，用来指导 LLM 输出我们想要的格式，然后解析 LLM 的输出")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("output_parsers "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ResponseSchema\n"),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("output_parsers "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" StructuredOutputParser\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# define expected response fields")]),t._v("\ngift_schema "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ResponseSchema"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v("'gift'")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" description"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Is this xxx? Answer True if yes, False if no'")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# response should have multiple fields")]),t._v("\nresponse_schemas "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("gift_schema"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create output parser")]),t._v("\noutput_parser "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" StructuredOutputParser"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_response_schemas"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("response_schemas"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create format instruction prompt string")]),t._v("\nformat_instructions "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" output_parser"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_format_instructions"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),r("p",[t._v("通过以上代码，我们表达了我们希望输出里面包含一个名为"),r("code",{pre:!0},[t._v("gift")]),t._v("的字段，这个字段的值应该是一个布尔值，然后让"),r("code",{pre:!0},[t._v("StructuredOutputParser")]),t._v("生成一个格式化指令字符串，用来告诉 LLM 我们希望输出的格式")]),t._v(" "),r("p",[t._v("接下来我们需要把 output parser 给出的 format instruction 放到 prompt template 里面，比如")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[r("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\\\nFor the following text, extract the following information:\n\ngift: Was the item purchased as a gift for someone else? \\\nAnswer True if yes, False if not or unknown.\n\ndelivery_days: How many days did it take for the product\\\nto arrive? If this information is not found, output -1.\n\nprice_value: Extract any sentences about the value or price,\\\nand output them as a comma separated Python list.\n\ntext: {text}\n\n{format_instructions}\n"""')]),t._v("\n")])]),t._v(" "),r("p",[t._v("这样 LLM 就会输出可以被 output parser 解析的数据（比如 JSON），我们就可以使用 output parser 来解析输出")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[t._v("output_dict "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" output_parser"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("response"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("content"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),r("h3",{attrs:{id:"memory"}},[t._v("Memory")]),t._v(" "),r("p",[t._v("与 LLM 的交互是无状态的，所以为了使 LLM 能够记住之前的信息，每次向 LLM 发出请求都要包含之前的聊天记录。langchain 提供了 Memory 来简化历史信息的管理")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("chains "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ConversationChain\n"),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("memory "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ConversationBufferMemory\n\nmemory "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ConversationBufferMemory"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nconversation "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ConversationChain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    llm"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    memory "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" memory"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    verbose"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nconversation"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),r("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Hi, my name is Andrew"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nconversation"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),r("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"What is 1+1?"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nconversation"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),r("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"What is my name?"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),r("p",[t._v("在如上的示例中，所有聊天历史记录都会保存在"),r("code",{pre:!0},[t._v("memory")]),t._v("里面，然后在每次向 LLM 发出请求的时候，都会把历史记录放到请求里面。所以当我们问"),r("code",{pre:!0},[t._v("What is my name?")]),t._v("的时候，LLM 会知道我们之前说过"),r("code",{pre:!0},[t._v("Hi, my name is Andrew")]),t._v("，所以会回答"),r("code",{pre:!0},[t._v("Andrew")])]),t._v(" "),r("p",[t._v("我们可以把 memory 里面的数据导出来放到外部数据库，也可以向 memory 导入曾经的历史数据，或者直接向里面写入新的数据")]),t._v(" "),r("p",[t._v("langchain 提供了很多不同功能的 memory 以便我们使用")]),t._v(" "),r("ul",[r("li",[r("code",{pre:!0},[t._v("ConversationBufferMemory")]),t._v("：把所有历史记录保存在内存里面")]),t._v(" "),r("li",[r("code",{pre:!0},[t._v("ConversationBufferWindowMemory")]),t._v("：把最近的历史记录保存在内存里面，超过一定数量的历史记录会被删除（基于消息的滑动窗口）")]),t._v(" "),r("li",[r("code",{pre:!0},[t._v("ConversationTokenBufferMemory")]),t._v("：把最近的历史记录保存在内存里面，按照 LLM 定义的 token 数量删除历史记录（基于 token 的滑动窗口）")]),t._v(" "),r("li",[r("code",{pre:!0},[t._v("ConversationSummaryMemory")]),t._v("：使用 LLM 获取历史记录的摘要，然后把摘要保存在内存里面")])]),t._v(" "),r("h3",{attrs:{id:"chain"}},[t._v("Chain")]),t._v(" "),r("p",[t._v("使用 Chain 把不同步骤组合起来，这样的话一次输入就可以产生多次 LLM 的调用，用来实现不同的功能")]),t._v(" "),r("h4",{attrs:{id:"simplesequentialchain"}},[t._v("SimpleSequentialChain")]),t._v(" "),r("p",[t._v("最简单的 Chain 是 SimpleSequentialChain，它只是把多个 LLM 调用串联起来，每个 LLM 的输入都是上一个 LLM 的输出")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[t._v("llm "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ChatOpenAI"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("temperature"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.9")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("llm_model"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# prompt template 1")]),t._v("\nfirst_prompt "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ChatPromptTemplate"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_template"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v('\n    "What '),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" the best name to describe \\\n    a company that makes "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("product"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v('?"\n'),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Chain 1")]),t._v("\nchain_one "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LLMChain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" prompt"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("first_prompt"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# prompt template 2")]),t._v("\nsecond_prompt "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ChatPromptTemplate"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_template"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v('\n    "Write a '),r("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),t._v(" words description "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" the following \\\n    company"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("company_name"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v('"\n'),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# chain 2")]),t._v("\nchain_two "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LLMChain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" prompt"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("second_prompt"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# link chains together")]),t._v("\noverall_simple_chain "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SimpleSequentialChain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  chains"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("chain_one"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" chain_two"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  verbose"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\noverall_simple_chain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("product"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),r("h4",{attrs:{id:"sequentialchain"}},[t._v("SequentialChain")]),t._v(" "),r("p",[t._v("另一个简单的 Chain 是 SequentialChain，它可以把多个 LLM 调用串联起来，但是没有输出和输入的一一对应关系")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# prompt template 1: translate to english")]),t._v("\nfirst_prompt "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ChatPromptTemplate"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_template"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Translate the following review to english:"')]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\n\\n{Review}"')]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# chain 1: input= Review and output= English_Review")]),t._v("\nchain_one "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LLMChain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" prompt"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("first_prompt"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                     output_key"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"English_Review"')]),t._v("\n                    "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsecond_prompt "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ChatPromptTemplate"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_template"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Can you summarize the following review in 1 sentence:"')]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\n\\n{English_Review}"')]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# chain 2: input= English_Review and output= summary")]),t._v("\nchain_two "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LLMChain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" prompt"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("second_prompt"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                     output_key"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"summary"')]),t._v("\n                    "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# prompt template 3: translate to english")]),t._v("\nthird_prompt "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ChatPromptTemplate"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_template"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"What language is the following review:\\n\\n{Review}"')]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# chain 3: input= Review and output= language")]),t._v("\nchain_three "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LLMChain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" prompt"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("third_prompt"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                       output_key"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"language"')]),t._v("\n                      "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# prompt template 4: follow up message")]),t._v("\nfourth_prompt "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ChatPromptTemplate"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_template"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Write a follow up response to the following "')]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"summary in the specified language:"')]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\n\\nSummary: {summary}\\n\\nLanguage: {language}"')]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# chain 4: input= summary, language and output= followup_message")]),t._v("\nchain_four "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LLMChain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" prompt"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("fourth_prompt"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                      output_key"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"followup_message"')]),t._v("\n                     "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# overall_chain: input= Review")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# and output= English_Review,summary, followup_message")]),t._v("\noverall_chain "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SequentialChain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    chains"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("chain_one"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" chain_two"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" chain_three"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" chain_four"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    input_variables"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Review"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    output_variables"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"English_Review"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"summary"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"followup_message"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    verbose"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),r("p",[t._v("可以看到，相比于 SimpleSequentialChain，SequentialChain 需要每个子链都指定输出的变量名，也就是 output_key（毕竟每个 LLM 调用只有一个输出），然后在其他子链里面直接在 prompt template 里面使用即可。SequentialChain 会自动根据 prompt 判断调用关系，形成 DAG 图，然后按顺序调用 LLM")]),t._v(" "),r("h4",{attrs:{id:"router-chain"}},[t._v("Router Chain")]),t._v(" "),r("p",[t._v("用来实现条件判断，然后选择不同的子链进行后续操作")]),t._v(" "),r("p",[t._v("比如我们设计了一个问答机器人，可以回答以下四个门类的问题")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[t._v("physics_template "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""You are a very smart physics professor. \\\nYou are great at answering questions about physics in a concise\\\nand easy to understand manner. \\\nWhen you don\'t know the answer to a question you admit\\\nthat you don\'t know.\n\nHere is a question:\n{input}"""')]),t._v("\n\n\nmath_template "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""You are a very good mathematician. \\\nYou are great at answering math questions. \\\nYou are so good because you are able to break down \\\nhard problems into their component parts,\nanswer the component parts, and then put them together\\\nto answer the broader question.\n\nHere is a question:\n{input}"""')]),t._v("\n\nhistory_template "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""You are a very good historian. \\\nYou have an excellent knowledge of and understanding of people,\\\nevents and contexts from a range of historical periods. \\\nYou have the ability to think, reflect, debate, discuss and \\\nevaluate the past. You have a respect for historical evidence\\\nand the ability to make use of it to support your explanations \\\nand judgements.\n\nHere is a question:\n{input}"""')]),t._v("\n\n\ncomputerscience_template "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('""" You are a successful computer scientist.\\\nYou have a passion for creativity, collaboration,\\\nforward-thinking, confidence, strong problem-solving capabilities,\\\nunderstanding of theories and algorithms, and excellent communication \\\nskills. You are great at answering coding questions. \\\nYou are so good because you know how to solve a problem by \\\ndescribing the solution in imperative steps \\\nthat a machine can easily interpret and you know how to \\\nchoose a solution that has a good balance between \\\ntime complexity and space complexity.\n\nHere is a question:\n{input}"""')]),t._v("\n\nprompt_infos "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n  "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"physics"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"description"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Good for answering questions about physics"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"prompt_template"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" physics_template\n  "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"math"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"description"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Good for answering math questions"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"prompt_template"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" math_template\n  "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"History"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"description"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Good for answering history questions"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"prompt_template"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" history_template\n  "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"computer science"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"description"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Good for answering computer science questions"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"prompt_template"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" computerscience_template\n  "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])]),t._v(" "),r("p",[t._v("为这四个门类创建四个子链，保存在 destination_chains 里面")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[t._v("destination_chains "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" p_info "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" prompt_infos"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    name "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" p_info"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    prompt_template "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" p_info"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"prompt_template"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    prompt "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ChatPromptTemplate"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_template"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("template"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("prompt_template"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    chain "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LLMChain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" prompt"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("prompt"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    destination_chains"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("name"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" chain\n")])]),t._v(" "),r("p",[t._v("为这四个子链提供描述，以便放到 prompt template 里面")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[t._v("destinations "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),r("span",{pre:!0,attrs:{class:"token string-interpolation"}},[r("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"')]),r("span",{pre:!0,attrs:{class:"token interpolation"}},[r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("p"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v("'name'")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v(": ")]),r("span",{pre:!0,attrs:{class:"token interpolation"}},[r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("p"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v("'description'")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),t._v(" "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" p "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" prompt_infos"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\ndestinations_str "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\n"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("join"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("destinations"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),r("p",[t._v("以免用户的问题不属于这四个门类，再添加一条默认子链")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[t._v("default_prompt "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ChatPromptTemplate"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_template"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{input}"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndefault_chain "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LLMChain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" prompt"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("default_prompt"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),r("p",[t._v("为 router 设计 prompt template")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[t._v("MULTI_PROMPT_ROUTER_TEMPLATE "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""Given a raw text input to a \\\nlanguage model select the model prompt best suited for the input. \\\nYou will be given the names of the available prompts and a \\\ndescription of what the prompt is best suited for. \\\nYou may also revise the original input if you think that revising\\\nit will ultimately lead to a better response from the language model.\n\n<< FORMATTING >>\nReturn a markdown code snippet with a JSON object formatted to look like:\n```json\n{{{{\n    "destination": string \\ name of the prompt to use or "DEFAULT"\n    "next_inputs": string \\ a potentially modified version of the original input\n}}}}\n```\n\nREMEMBER: "destination" MUST be one of the candidate prompt \\\nnames specified below OR it can be "DEFAULT" if the input is not\\\nwell suited for any of the candidate prompts.\nREMEMBER: "next_inputs" can just be the original input \\\nif you don\'t think any modifications are needed.\n\n<< CANDIDATE PROMPTS >>\n{destinations}\n\n<< INPUT >>\n{{input}}\n\n<< OUTPUT (remember to include the ```json)>>"""')]),t._v("\n")])]),t._v(" "),r("p",[t._v("可以看到，判断用户的输入属于哪个门类，也是 LLM 的工作之一")]),t._v(" "),r("p",[t._v("然后我们创建 RouterChain")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[t._v("router_template "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" MULTI_PROMPT_ROUTER_TEMPLATE"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),r("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  destinations"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("destinations_str\n"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrouter_prompt "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" PromptTemplate"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  template"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("router_template"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  input_variables"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"input"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  output_parser"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("RouterOutputParser"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrouter_chain "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LLMRouterChain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_llm"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" router_prompt"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),r("p",[t._v("Router 只负责判断用户输入的门类，我们还需要一个 MultiPromptChain 来连接之前创建的四个子链和一个默认子链")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[t._v("chain "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" MultiPromptChain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  router_chain"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("router_chain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  destination_chains"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("destination_chains"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  default_chain"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("default_chain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" verbose"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),r("p",[t._v("构建完毕，我们可以问它问题了，比如如下一个物理问题")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[t._v("chain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"What is black body radiation?"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),r("h3",{attrs:{id:"question-and-answer"}},[t._v("Question and Answer")]),t._v(" "),r("h4",{attrs:{id:"快速实现"}},[t._v("快速实现")]),t._v(" "),r("p",[t._v("实现一个从 CSV 中查询某些行的应用：")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("chains "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" RetrievalQA\n"),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("chat_models "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ChatOpenAI\n"),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("document_loaders "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" CSVLoader\n"),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vectorstores "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" DocArrayInMemorySearch\n"),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("indexes "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" VectorstoreIndexCreator\n"),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" IPython"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("display "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" display"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Markdown\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Load a CSV file into a list of Documents.")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Each document represents one row of the CSV file.")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Every row is converted into a key/value pair and outputted to a new line in the document’s page_content.")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v("'OutdoorClothingCatalog_1000.csv'")]),t._v("\nloader "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" CSVLoader"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file_path"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create an index wrapper for easy access")]),t._v("\nindex "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" VectorstoreIndexCreator"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# store embedding vectors in memory")]),t._v("\n    vectorstore_cls"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("DocArrayInMemorySearch\n"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_loaders"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("loader"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create a vectorstore index from loaders.")]),t._v("\n\nquery "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v('"Please '),r("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("all")]),t._v(" your shirts "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" sun protection \\\n"),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" a table "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" markdown "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" summarize each one"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v('"\n\n'),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# query with the default LLM (OpenAI)")]),t._v("\nresponse "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" index"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("query"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("query"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ndisplay"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Markdown"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("response"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),r("h4",{attrs:{id:"底层逻辑"}},[t._v("底层逻辑")]),t._v(" "),r("ol",[r("li",[t._v("LLM 对数据进行 embedding，获得向量，并保存到数据库")]),t._v(" "),r("li",[t._v("LLM 对 query 进行 embedding，获得向量")]),t._v(" "),r("li",[t._v("从数据库中找到与 query 向量相似的向量，然后返回对应的数据")]),t._v(" "),r("li",[t._v("把数据和 query 交给 LLM，返回人类语言描述的结果")])]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("document_loaders "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" CSVLoader\n"),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("embeddings "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" OpenAIEmbeddings\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# load CSV file into documents")]),t._v("\nloader "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" CSVLoader"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file_path"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndocs "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" loader"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# index documents with OpenAI embeddings")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# and store them in memory")]),t._v("\nembeddings "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" OpenAIEmbeddings"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndb "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" DocArrayInMemorySearch"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_documents"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  docs"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  embeddings\n"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# we can embed a query")]),t._v("\nembed "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" embeddings"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("embed_query"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Hi my name is Harrison"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# or directly search for similar documents")]),t._v("\ndocs "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" db"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("similarity_search"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("query"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# we need to feed the search results to LLM")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# so we create a retriever")]),t._v("\nretriever "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" db"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("as_retriever"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create a RetrievalQA chain")]),t._v("\nqa_stuff "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RetrievalQA"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_chain_type"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    llm"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    chain_type"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"stuff"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    retriever"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("retriever"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    verbose"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# now we can run a query")]),t._v("\nresponse "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" qa_stuff"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("query"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),r("h4",{attrs:{id:"chain-type"}},[t._v("Chain Type")]),t._v(" "),r("p",[t._v("上述的示例使用了"),r("code",{pre:!0},[t._v("stuff")]),t._v("作为 RetrievalQA 的 chain type，这个 chain type 会把所有搜索结果交给 LLM")]),t._v(" "),r("p",[t._v("如果搜索结果太多/太大，就不好使了。以下是其他 Chain Type")]),t._v(" "),r("p",[r("img",{attrs:{src:e(501),alt:"0"}})]),t._v(" "),r("h3",{attrs:{id:"evaluation"}},[t._v("Evaluation")]),t._v(" "),r("p",[t._v("如何评估 LLM 的表现？或者说 LLM 在回答问题上的正确率？")]),t._v(" "),r("h4",{attrs:{id:"手动给出-ground-truth"}},[t._v("手动给出 ground truth")]),t._v(" "),r("p",[t._v("针对一个 context（比如：数据集），手动给出 query 和 answer")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[t._v("examples "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"query"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(' "Do the Cozy Comfort Pullover Set\\\n        have side pockets?"'),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"answer"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Yes"')]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"query"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(' "What collection '),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" the Ultra"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("Lofty \\\n        "),r("span",{pre:!0,attrs:{class:"token number"}},[t._v("850")]),t._v(" Stretch Down Hooded Jacket "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v('?"'),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"answer"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"The DownTek collection"')]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])]),t._v(" "),r("h4",{attrs:{id:"使用-llm-自动化生成-ground-truth"}},[t._v("使用 LLM 自动化生成 ground truth")]),t._v(" "),r("p",[t._v("使用 QAGenerateChain，从文档中生成 question-answer-pair")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("evaluation"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("qa "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" QAGenerateChain\nexample_gen_chain "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" QAGenerateChain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_llm"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ChatOpenAI"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("llm_model"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nnew_examples "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" example_gen_chain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apply_and_parse"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"doc"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" t"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" t "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" data"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),r("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),r("h4",{attrs:{id:"评估-llm"}},[t._v("评估 LLM")]),t._v(" "),r("p",[t._v("有了 ground truth，就可以对 LLM 的返回结果进行评估了")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get predict results")]),t._v("\npredictions "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" qa"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),r("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("apply")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("examples"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# compare predictions with ground truth")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("evaluation"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("qa "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" QAEvalChain\neval_chain "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" QAEvalChain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_llm"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ngraded_outputs "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" eval_chain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("evaluate"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("examples"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" predictions"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),r("p",[t._v("因为 LLM 的随机性，使用 "),r("code",{pre:!0},[t._v("QAGenerateChain")]),t._v(" 生成的答案，和 "),r("code",{pre:!0},[t._v("RetrievalQA")]),t._v(" 找到的答案，可能表达方式不一样，但是表达的意思是一样的，所以使用 "),r("code",{pre:!0},[t._v("QAEvalChain")]),t._v(" 评估二者的意思是否相同")]),t._v(" "),r("h3",{attrs:{id:"agents"}},[t._v("Agents")]),t._v(" "),r("p",[t._v("使用 Agents 和外部环境交互，从而实现更多的功能")]),t._v(" "),r("blockquote",[r("p",[t._v("为了消除随机性，可以把 LLM 的 temperature 设置为 0，以确保 LLM 返回的结果的准确性")])]),t._v(" "),r("h4",{attrs:{id:"示例"}},[t._v("示例")]),t._v(" "),r("p",[t._v("以下为一个示例")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("agents"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("agent_toolkits "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" create_python_agent\n"),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("agents "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" load_tools"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" initialize_agent\n"),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("agents "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" AgentType\n"),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tools"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("python"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tool "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" PythonREPLTool\n"),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("python "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" PythonREPL\n"),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("chat_models "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ChatOpenAI\n\nllm "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ChatOpenAI"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("temperature"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("llm_model"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# llm-math是一个使用LLM和计算器解决数学问题的chain")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# wikipedia是一个连接维基百科API的chain，用来实现搜索")]),t._v("\ntools "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" load_tools"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"llm-math"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"wikipedia"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" llm"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("llm"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nagent "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" initialize_agent"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    tools"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    llm"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用Chat大模型")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用ReAct模型实现prompt engineering")]),t._v("\n    agent"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("AgentType"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("CHAT_ZERO_SHOT_REACT_DESCRIPTION"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果LLM的输出无法被解析，则让LLM解析这个输出并进行自动修正")]),t._v("\n    handle_parsing_errors"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    verbose "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),r("p",[t._v("现在我们用这个 agent 计算一个数学问题")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[t._v("agent"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"What is the 25% of 300?"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),r("p",[t._v("Agent 会判断：应该使用 Calculator，并且输入是"),r("code",{pre:!0},[t._v("300*0.25")]),t._v("。然后调用外部计算器的 API，返回"),r("code",{pre:!0},[t._v("75.0")])]),t._v(" "),r("p",[t._v("同理，我们可以让 Agent 帮我们查维基百科，或者执行代码")]),t._v(" "),r("h4",{attrs:{id:"自定义-tool"}},[t._v("自定义 tool")]),t._v(" "),r("p",[t._v("非常简单，只需要给一个函数加上"),r("code",{pre:!0},[t._v("@tool")]),t._v("装饰器即可")]),t._v(" "),r("p",[t._v("我们必须给函数加上 docstring，这样 Agent 才能知道这个函数的功能，以便在合适的时候调用")]),t._v(" "),r("pre",{staticClass:"language-py"},[r("code",{pre:!0,attrs:{class:"language-py"}},[r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" langchain"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("agents "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tool\n"),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" datetime "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" date\n\n"),r("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@tool")]),t._v("\n"),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token function"}},[t._v("time")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("text"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""Returns todays date, use this for any \\\n    questions related to knowing todays date. \\\n    The input should always be an empty string, \\\n    and this function will always return todays \\\n    date - any date mathmatics should occur \\\n    outside this function."""')]),t._v("\n    "),r("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),r("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("date"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("today"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])}]};t.exports={attributes:{title:"LangChain 101"},vue:{render:r.render,staticRenderFns:r.staticRenderFns,component:{data:function(){return{templateRender:null}},render:function(t){return this.templateRender?this.templateRender():t("div","Rendering")},created:function(){this.templateRender=r.render,this.$options.staticRenderFns=r.staticRenderFns}}}}},501:function(t,n,e){t.exports=e.p+"img/60-0.adb1cba.png"}}]);