(window.webpackJsonp=window.webpackJsonp||[]).push([[123],{1157:function(t,e){const v={render:function(){var t=this;t.$createElement;return t._self._c,t._m(0)},staticRenderFns:[function(){var t=this,e=t.$createElement,v=t._self._c||e;return v("div",{staticClass:"frontmatter-markdown"},[v("h2",{attrs:{id:"前言"}},[t._v("前言")]),t._v(" "),v("p",[t._v("本文是观看"),v("a",{attrs:{href:"https://www.bilibili.com/video/BV1EZ4y1G7iL"}},[t._v("此视频")]),t._v("时的笔记")]),t._v(" "),v("h2",{attrs:{id:"hive"}},[t._v("Hive")]),t._v(" "),v("h3",{attrs:{id:"概述"}},[t._v("概述")]),t._v(" "),v("ul",[v("li",[t._v("基于Hadoop的数据仓库")]),t._v(" "),v("li",[t._v("使用HQL（Hive风格的SQL）进行操作")]),t._v(" "),v("li",[t._v("本质是把HQL转换为MapReduce程序，数据存在HDFS，调度用Yarn。所以Hive可以视为Hadoop的一个客户端，不需要集群\n"),v("ul",[v("li",[t._v("把SQL语言中常见的select/where/insert/group等操作映射到MapReduce代码")]),t._v(" "),v("li",[t._v("计算引擎是可以修改的，不一定是MapReduce，也可以是Spark、Tez之类的。在Hive 2中MR已经过时，建议使用Spark/tez")])])]),t._v(" "),v("li",[t._v("适合一次写入、多次查询的业务负载")]),t._v(" "),v("li",[t._v("最初由Facebook开源，用来解决海量结构化日志统计")]),t._v(" "),v("li",[t._v("优点\n"),v("ul",[v("li",[t._v("类似SQL语法，简单容易上手，开发快速")]),t._v(" "),v("li",[t._v("开发人员不需要学习MapReduce，降低学习成本")]),t._v(" "),v("li",[t._v("底层是Hadoop，所以底层参数可以被调整，从而优化性能")]),t._v(" "),v("li",[t._v("支持自定义函数")])])]),t._v(" "),v("li",[t._v("缺点\n"),v("ul",[v("li",[t._v("基于MapReduce，执行延迟高，不适合实时任务和小数据量")]),t._v(" "),v("li",[t._v("HQL表达能力有限\n"),v("ul",[v("li",[t._v("无法使用HQL表达迭代式算法（循环）")]),t._v(" "),v("li",[t._v("不擅长数据挖掘，无法用MapReduce实现更高性能的算法")])])]),t._v(" "),v("li",[t._v("效率低\n"),v("ul",[v("li",[t._v("自动生成的MapReduce作业不够智能化")]),t._v(" "),v("li",[t._v("从Hive角度很难调优，还是要基于Hadoop调优")])])])])]),t._v(" "),v("li",[t._v("日志默认保存在"),v("code",{pre:!0},[t._v("/tmp/<username>")]),t._v("中。可以修改"),v("code",{pre:!0},[t._v("hive-log4j2.properties")]),t._v("文件中的"),v("code",{pre:!0},[t._v("hive.log.dir")]),t._v("来修改保存路径，比如"),v("code",{pre:!0},[t._v("/opt/module/hive/logs")])])]),t._v(" "),v("h3",{attrs:{id:"架构"}},[t._v("架构")]),t._v(" "),v("ul",[v("li",[t._v("Meta Store\n"),v("ul",[v("li",[t._v("保存元数据，比如表名和HDFS文件的映射、创建的表(create table)的信息\n"),v("ul",[v("li",[t._v("元数据会缓存表的行数、文件数等信息，从而加速"),v("code",{pre:!0},[t._v("select count(*)")]),t._v("之类的查询\n"),v("ul",[v("li",[t._v("使用"),v("code",{pre:!0},[t._v("insert")]),t._v("之类的语句会刷新这些缓存")])])]),t._v(" "),v("li",[t._v("默认映射关系："),v("code",{pre:!0},[t._v("tableName")]),t._v("在HDFS中的存储路径为"),v("code",{pre:!0},[t._v("hdfs://xxx:xxx/user/hive/warehouse/tableName")]),t._v(" "),v("ul",[v("li",[t._v("这个路径是一个文件夹，Hive会访问文件夹下的所有文件")]),t._v(" "),v("li",[t._v("所以"),v("code",{pre:!0},[t._v("select * from tableName")]),t._v("会查询此文件夹下的所有文件。所以写数据可以不通过Hive，可以直接put到HDFS里面")])])])])]),t._v(" "),v("li",[t._v("默认使用Apache Derby数据库（轻量，只支持单用户）。通常用改用MySQL\n"),v("ul",[v("li",[t._v("Derby数据库会在当前目录创建数据文件。如果在不同的目录启动Derby，是可以启动多个Derby的，但是这些进程不共享数据，所以还是单用户")])])]),t._v(" "),v("li",[t._v("metastore服务端\n"),v("ul",[v("li",[v("code",{pre:!0},[t._v("bin/hive --service metastore")]),t._v("启动metastore服务器\n"),v("ul",[v("li",[t._v("服务器是前台应用。可以使用"),v("code",{pre:!0},[t._v("honup hive --service metastore 2>&1 &")]),t._v("把app放到后台")])])]),t._v(" "),v("li",[t._v("修改配置文件里面的"),v("code",{pre:!0},[t._v("hive.metastore.uris")]),t._v("以应用此metastore服务。值为"),v("code",{pre:!0},[t._v("thrift://xxx:xxx")])])])]),t._v(" "),v("li",[t._v("需要使用"),v("code",{pre:!0},[t._v("bin/schematool -dbType mysql -initSchema")]),t._v("初始化元数据")])])]),t._v(" "),v("li",[t._v("Client\n"),v("ul",[v("li",[t._v("Hive CLI\n"),v("ul",[v("li",[t._v("默认情况是交互式CLI")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("-e")]),t._v("通过命令行传入SQL命令")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("-f")]),t._v("传入SQL文件")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("quit/exit")]),t._v("推出交互式CLI")]),t._v(" "),v("li",[t._v("可以执行HDFS命令，比如"),v("code",{pre:!0},[t._v("dfs fs /;")])]),t._v(" "),v("li",[t._v("命令历史保存在"),v("code",{pre:!0},[t._v("~/.hivehistory")])])])]),t._v(" "),v("li",[t._v("JDBC\n"),v("ul",[v("li",[t._v("需要启动"),v("code",{pre:!0},[t._v("hiveserver2")]),t._v("和"),v("code",{pre:!0},[t._v("metastore")]),t._v("服务\n"),v("ul",[v("li",[t._v("修改配置文件\n"),v("ul",[v("li",[v("code",{pre:!0},[t._v("hive.server2.thrift.bind.host")])]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("hive.server2.thrift.port")])])])]),t._v(" "),v("li",[t._v("启动hiveserver2服务："),v("code",{pre:!0},[t._v("bin/hive --service hiveserver2")]),t._v("或"),v("code",{pre:!0},[t._v("bin/hiveserver2")])]),t._v(" "),v("li",[t._v("启动metastore服务见上文")])])]),t._v(" "),v("li",[t._v("java代码使用Hive JDBC连接到hiveserver2，hiveserver2连接到metastore，metastore使用MySQL JDBC连接到MySQL获取元数据")]),t._v(" "),v("li",[t._v("也可以使用Hive JDBC CLI: "),v("code",{pre:!0},[t._v("bin/beeline -u jdbc:hive2://xx.xxx -n <username>")]),t._v(" "),v("ul",[v("li",[t._v("用户名是系统用户名")]),t._v(" "),v("li",[t._v("启动比较慢，建议等hiveserver2准备好了再操作")])])])])])])]),t._v(" "),v("li",[t._v("SQL Parser（解析器）\n"),v("ul",[v("li",[t._v("解析SQL")])])]),t._v(" "),v("li",[t._v("Physical Plan（编译器）\n"),v("ul",[v("li",[t._v("把解析后的SQL解释为MR任务")])])]),t._v(" "),v("li",[t._v("Query Optimizer（优化器）\n"),v("ul",[v("li",[t._v("优化SQL")])])]),t._v(" "),v("li",[t._v("Execution（执行器）\n"),v("ul",[v("li",[t._v("执行MR任务")])])])]),t._v(" "),v("h3",{attrs:{id:"数据仓库对比关系型数据库"}},[t._v("数据仓库对比关系型数据库")]),t._v(" "),v("ul",[v("li",[t._v("二者通常都使用类SQL语言")]),t._v(" "),v("li",[t._v("数据仓库数据量更大（比如Hive的数据存在分布式的HDFS里面），不建议经常更新数据，适合查询。而关系型数据库比较注重小数据量、实时、ACID读写、在线业务")]),t._v(" "),v("li",[t._v("数据仓库延迟较高。适合大数据量、并行任务")])]),t._v(" "),v("h3",{attrs:{id:"配置"}},[t._v("配置")]),t._v(" "),v("ul",[v("li",[v("code",{pre:!0},[t._v("hive-default.xml")]),t._v("服务端默认配置文件。保存了默认值")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("hive-site.xml")]),t._v("服务端配置文件。通常修改此文件来修改服务端配置")]),t._v(" "),v("li",[t._v("命令行参数："),v("code",{pre:!0},[t._v("bin/hive --hiveconf k=v")]),t._v("。单个会话生效")]),t._v(" "),v("li",[t._v("在客户端执行"),v("code",{pre:!0},[t._v("set;")]),t._v("可以查看配置和环境变量，执行"),v("code",{pre:!0},[t._v("set k=v;")]),t._v("可以修改配置，仅在单个会话生效")])]),t._v(" "),v("h3",{attrs:{id:"数据类型"}},[t._v("数据类型")]),t._v(" "),v("h4",{attrs:{id:"基本数据类型"}},[t._v("基本数据类型")]),t._v(" "),v("table",[v("thead",[v("tr",[v("th",[t._v("Hive数据类型")]),t._v(" "),v("th",[t._v("Java数据类型")]),t._v(" "),v("th",[t._v("细节")])])]),t._v(" "),v("tbody",[v("tr",[v("td",[t._v("TINYINT")]),t._v(" "),v("td",[t._v("byte")]),t._v(" "),v("td",[t._v("1字节有符号整数")])]),t._v(" "),v("tr",[v("td",[t._v("SMALINT")]),t._v(" "),v("td",[t._v("short")]),t._v(" "),v("td",[t._v("2字节有符号整数")])]),t._v(" "),v("tr",[v("td",[v("strong",[t._v("INT")])]),t._v(" "),v("td",[t._v("int")]),t._v(" "),v("td",[t._v("4字节有符号整数")])]),t._v(" "),v("tr",[v("td",[v("strong",[t._v("BIGINT")])]),t._v(" "),v("td",[t._v("long")]),t._v(" "),v("td",[t._v("8字节有符号整数")])]),t._v(" "),v("tr",[v("td",[t._v("BOOLEAN")]),t._v(" "),v("td",[t._v("boolean")]),t._v(" "),v("td",[t._v("true/false")])]),t._v(" "),v("tr",[v("td",[t._v("FLOAT")]),t._v(" "),v("td",[t._v("float")]),t._v(" "),v("td",[t._v("单精度浮点")])]),t._v(" "),v("tr",[v("td",[v("strong",[t._v("DOUBLE")])]),t._v(" "),v("td",[t._v("double")]),t._v(" "),v("td",[t._v("双精度浮点")])]),t._v(" "),v("tr",[v("td",[v("strong",[t._v("STRING")])]),t._v(" "),v("td",[t._v("string")]),t._v(" "),v("td",[t._v("字符串。可以指定字符集。使用单引号或双引号")])]),t._v(" "),v("tr",[v("td",[t._v("TIMESTAMP")]),t._v(" "),v("td",[t._v("-")]),t._v(" "),v("td",[t._v("时间")])]),t._v(" "),v("tr",[v("td",[t._v("BINARY")]),t._v(" "),v("td",[t._v("-")]),t._v(" "),v("td",[t._v("二进制字节数组")])])])]),t._v(" "),v("p",[t._v("hive的string相当于普通数据库的varchar，是可变字符串，但是不能声明最多可以保存多少字符。理论上最多2GB")]),t._v(" "),v("h4",{attrs:{id:"集合数据类型"}},[t._v("集合数据类型")]),t._v(" "),v("ul",[v("li",[t._v("STRUCT\n"),v("ul",[v("li",[t._v("类似C-like语言的struct，成员可以通过"),v("code",{pre:!0},[t._v(".")]),t._v("来访问")]),t._v(" "),v("li",[t._v("语法："),v("code",{pre:!0},[t._v("struct<street:string, city:string>")])])])]),t._v(" "),v("li",[t._v("MAP\n"),v("ul",[v("li",[t._v("键值对，使用"),v("code",{pre:!0},[t._v("['key']")]),t._v("访问成员")]),t._v(" "),v("li",[t._v("语法："),v("code",{pre:!0},[t._v("map<string, int>")])])])]),t._v(" "),v("li",[t._v("ARRAY\n"),v("ul",[v("li",[t._v("数组，起始编号为0")]),t._v(" "),v("li",[t._v("语法："),v("code",{pre:!0},[t._v("array<string>")])])])])]),t._v(" "),v("p",[t._v("集合数据类型支持嵌套")]),t._v(" "),v("p",[t._v("示例建表语句：")]),t._v(" "),v("pre",{staticClass:"language-sql"},[v("code",{pre:!0,attrs:{class:"language-sql"}},[v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" xxx "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n\tname string"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\tfriends array"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("string"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\tchildren map"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("string"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- name=>age")]),t._v("\n\taddress struct"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("street:string"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" city:string"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("row")]),t._v(" format delimited\n\t"),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fields")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("terminated")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token string"}},[t._v("','")]),t._v("\n\tcollection items "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("terminated")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token string"}},[t._v("'_'")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- struct/map/array的分隔符")]),t._v("\n\tmap "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("keys")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("terminated")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token string"}},[t._v("':'")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- map中k/v的分隔符")]),t._v("\n\t"),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lines")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("terminated")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\n'")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),v("p",[t._v("示例数据：")]),t._v(" "),v("pre",{staticClass:"language-csv"},[v("code",{pre:!0,attrs:{class:"language-csv"}},[v("span",{pre:!0,attrs:{class:"token value"}},[t._v("DiscreteTom")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),v("span",{pre:!0,attrs:{class:"token value"}},[t._v("friend1_friend2")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),v("span",{pre:!0,attrs:{class:"token value"}},[t._v("child1:18_child2:19")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),v("span",{pre:!0,attrs:{class:"token value"}},[t._v("BUPT_Beijing")]),t._v("\n")])]),t._v(" "),v("p",[t._v("查询数据：")]),t._v(" "),v("pre",{staticClass:"language-sql"},[v("code",{pre:!0,attrs:{class:"language-sql"}},[v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" children"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),v("span",{pre:!0,attrs:{class:"token string"}},[t._v("'child1'")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" address"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("street "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" xxx"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),v("h4",{attrs:{id:"类型转换"}},[t._v("类型转换")]),t._v(" "),v("p",[t._v("基本数据类型支持隐式转换，类似于java里面的类型转换。转换条件是不能丢失信息量，比如TINYINT可以转换为INT，但是INT不能隐式转换为TINYINT，除非使用CAST进行显式转换")]),t._v(" "),v("ul",[v("li",[t._v("所有整数类型都可以隐式转换为范围更广的整数类型")]),t._v(" "),v("li",[t._v("整数类型、FLOAT、"),v("strong",[t._v("STRING")]),t._v("都可以隐式转换为DOUBLE\n"),v("ul",[v("li",[t._v("如果STRING里面的内容正好是小数格式，比如"),v("code",{pre:!0},[t._v("'123.456'")]),t._v("则可以转换为DOUBLE")])])]),t._v(" "),v("li",[t._v("TINYINT/SMALLINT/INT可以转换为FLOAT")]),t._v(" "),v("li",[t._v("BOOLEAN不能转换")])]),t._v(" "),v("p",[t._v("强制类型转换："),v("code",{pre:!0},[t._v("cast(xxx as int)")])]),t._v(" "),v("p",[t._v("例："),v("code",{pre:!0},[t._v("select '1'+2, cast('1' as int) + 2;")]),t._v("，输出是"),v("code",{pre:!0},[t._v("3.0 3")]),t._v("，即第一个结果是DOUBLE，第二个是INT")]),t._v(" "),v("h3",{attrs:{id:"操作"}},[t._v("操作")]),t._v(" "),v("h4",{attrs:{id:"ddl"}},[t._v("DDL")]),t._v(" "),v("h5",{attrs:{id:"数据库级别"}},[t._v("数据库级别")]),t._v(" "),v("p",[t._v("创建数据库：")]),t._v(" "),v("pre",{staticClass:"language-sql"},[v("code",{pre:!0,attrs:{class:"language-sql"}},[v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("database")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("not")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("exists")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("database")]),t._v(" name"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("COMMENT")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("comment")]),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("LOCATION "),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("hdfs path"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WITH")]),t._v(" DBPROPERTIES "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("v"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),v("ul",[v("li",[v("code",{pre:!0},[t._v("show <DDL>")]),t._v("来查看某个语句实际执行的时候，默认参数是什么样子的，比如"),v("code",{pre:!0},[t._v("show create table xxx;")])]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("show databases;")]),t._v("查看数据库")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("use <database>;")]),t._v("切换数据库")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("show databases like 'xxx*';")]),t._v("查看名字符合条件的数据库")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("desc database <name>;")]),t._v("查看数据库信息")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("desc database extended <name>;")]),t._v("查看数据库详细信息")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("alter database xxx set dbproperties(k=v);")]),t._v("修改数据库")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("drop database [if exists] xxx;")]),t._v("删除数据库\n"),v("ul",[v("li",[t._v("如果数据库不为空（存在表），可以使用"),v("code",{pre:!0},[t._v("drop database xxx cascade;")]),t._v("进行强制删除。HDFS里面的文件也会被删除")])])])]),t._v(" "),v("h5",{attrs:{id:"表级别"}},[t._v("表级别")]),t._v(" "),v("p",[t._v("创建表：")]),t._v(" "),v("pre",{staticClass:"language-sql"},[v("code",{pre:!0,attrs:{class:"language-sql"}},[v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("external"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("not")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("exists")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" name"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("col name"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("data")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("comment")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("comment")]),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("comment")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("comment")]),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("partitioned "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("col name"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("data")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("comment")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("comment")]),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 分区")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("clustered")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("col name"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 分桶")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("sorted "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("col name"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ASC")]),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DESC")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("into")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("num"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" buckets"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 分桶")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("row")]),t._v(" format "),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("row")]),t._v(" format"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("stored "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("file")]),t._v(" format"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 压缩格式。默认不压缩")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("location "),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("hdfs path"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("tblproperties "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("k"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("v"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" statement"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])]),t._v(" "),v("ul",[v("li",[t._v("内部表vs外部表\n"),v("ul",[v("li",[t._v("内部表（管理表，managed），由hive控制数据生命周期。删除一个内部表时，hive除了会删除元数据，还会删除HDFS中的数据")]),t._v(" "),v("li",[t._v("外部表：hive认为自己不拥有数据。删除表时仅删除元数据，不会删除HDFS中的数据")]),t._v(" "),v("li",[t._v("修改表："),v("code",{pre:!0},[t._v("alter table xxx set tblproperties('EXTERNAL'='TRUE|FALSE');")])]),t._v(" "),v("li",[t._v("查询表类型："),v("code",{pre:!0},[t._v("desc formatted xxx;")])])])]),t._v(" "),v("li",[t._v("重命名表："),v("code",{pre:!0},[t._v("alter table <name> rename to <name>;")])]),t._v(" "),v("li",[t._v("更新列："),v("code",{pre:!0},[t._v("alter table <name> change [column] <old name> <new name> <type> [comment <comment>] [first|after <col name>]")])]),t._v(" "),v("li",[t._v("增加和替换列："),v("code",{pre:!0},[t._v("alter table <name> add|replace columns (<name> <type> [commen <comment>], ...);")]),t._v(" "),v("ul",[v("li",[t._v("ADD表示添加字段，在所有列后面（partition列前）")]),t._v(" "),v("li",[t._v("REPLACE表示替换表中所有字段")])])])]),t._v(" "),v("h4",{attrs:{id:"dml"}},[t._v("DML")]),t._v(" "),v("h5",{attrs:{id:"导入数据"}},[t._v("导入数据")]),t._v(" "),v("ul",[v("li",[t._v("导入已存在的表："),v("code",{pre:!0},[t._v("load data [local] inpath <path> [overwrite] into table <name> [partition (k=v, ...)];")]),t._v(" "),v("ul",[v("li",[t._v("如果使用了"),v("code",{pre:!0},[t._v("local")]),t._v("则把本地数据加载到Hive表。否则从hdfs加载数据\n"),v("ul",[v("li",[t._v("如果是从本地加载数据，则数据会被"),v("strong",[t._v("复制")]),t._v("到HDFS中。使用HDFS API")]),t._v(" "),v("li",[t._v("如果从hdfs加载数据，数据会被"),v("strong",[t._v("移动")]),t._v("到目标位置，而不是复制。只需要修改HDFS的NameNode元数据，很快")])])]),t._v(" "),v("li",[t._v("如果使用了"),v("code",{pre:!0},[t._v("overwrite")]),t._v("则删除原表内数据。否则，追加数据")]),t._v(" "),v("li",[t._v("相比于使用"),v("code",{pre:!0},[t._v("hdfs put")]),t._v("的方法上传数据，使用"),v("code",{pre:!0},[t._v("load data")]),t._v("会刷新原数据里面的文件数等信息\n"),v("ul",[v("li",[t._v("但是不会刷新表的行数")]),t._v(" "),v("li",[t._v("使用"),v("code",{pre:!0},[t._v("insert")]),t._v("可以同时刷新文件数和行数")])])])])]),t._v(" "),v("li",[t._v("查询插入："),v("code",{pre:!0},[t._v("insert into|overwrite table <name> select xx, xx from xxx where xxx;")]),t._v(" "),v("ul",[v("li",[v("code",{pre:!0},[t._v("insert into")]),t._v("插入数据")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("insert overwrite")]),t._v("覆盖数据")]),t._v(" "),v("li",[t._v("可以插入回原表。使用此方式更新整个表可能比update语句更合适")])])]),t._v(" "),v("li",[t._v("分区插入：")])]),t._v(" "),v("pre",{staticClass:"language-sql"},[v("code",{pre:!0,attrs:{class:"language-sql"}},[v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" xxx\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("insert")]),t._v(" overwrite "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" xxx "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("v"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" xxx "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" condition1\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("insert")]),t._v(" overwrite "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" xxx "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("v"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" xxx "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" condition2"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),v("ul",[v("li",[t._v("建表并从查询加载数据："),v("code",{pre:!0},[t._v("create table if not exists xxx as select xxx from xxx;")])]),t._v(" "),v("li",[t._v("建表并从HDFS加载数据"),v("code",{pre:!0},[t._v("create external table xx (xxx xxx) location '/xxx';")])]),t._v(" "),v("li",[t._v("使用import命令导入之前使用export命令导出的数据："),v("code",{pre:!0},[t._v("import table xxx from '/path';")])])]),t._v(" "),v("h5",{attrs:{id:"导出数据"}},[t._v("导出数据")]),t._v(" "),v("ul",[v("li",[t._v("可以直接下载HDFS里面的文件")]),t._v(" "),v("li",[t._v("把查询结果保存到本地目录"),v("code",{pre:!0},[t._v("insert overwrite [local] directory '/path' select xx from xxx;")])]),t._v(" "),v("li",[t._v("export: "),v("code",{pre:!0},[t._v("export table xxx to '/path';")]),t._v(" "),v("ul",[v("li",[t._v("使用export导出的数据会包含元数据")]),t._v(" "),v("li",[t._v("主要用于Hive/Hadoop迁移")])])]),t._v(" "),v("li",[t._v("CLI + 输出重定向")]),t._v(" "),v("li",[t._v("清空表："),v("code",{pre:!0},[t._v("truncate table xxx;")]),t._v(" "),v("ul",[v("li",[t._v("只能删除内部表，无法操作外部表")])])]),t._v(" "),v("li",[t._v("Sqoop，用来把数据导出到MySQL，详见下文")])]),t._v(" "),v("h5",{attrs:{id:"查询数据"}},[t._v("查询数据")]),t._v(" "),v("pre",{staticClass:"language-sql"},[v("code",{pre:!0,attrs:{class:"language-sql"}},[v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("all")]),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("distinct")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" xxx"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" xxx"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" xxx\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" xxx"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("group")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" xxx"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" xxx"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("cluster "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" xxx "),v("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("distribute "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" xxx"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("sort "),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" xxx"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("limit")]),t._v(" xxx"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),v("p",[t._v("和普通的SQL类似。略")]),t._v(" "),v("h3",{attrs:{id:"分区"}},[t._v("分区")]),t._v(" "),v("ul",[v("li",[t._v("Hive的分区就是在HDFS上分目录保存数据\n"),v("ul",[v("li",[t._v("目录名就是分区的k/v值。所以用来分区的field不在文件中，而是文件名")]),t._v(" "),v("li",[t._v("并行任务")]),t._v(" "),v("li",[t._v("避免全表扫描")]),t._v(" "),v("li",[t._v("分区信息会保存在元数据中")])])]),t._v(" "),v("li",[t._v("创建分区表：在"),v("code",{pre:!0},[t._v("create table")]),t._v("的时候使用"),v("code",{pre:!0},[t._v("partitioned by(<field name> <type>)")])]),t._v(" "),v("li",[t._v("向分区加载数据："),v("code",{pre:!0},[t._v("load data inpath '/path' into table xxx partition(k=v);")]),t._v(" "),v("ul",[v("li",[t._v("如果不指定partition，则partition的值为"),v("code",{pre:!0},[t._v("__HIVE_DEFAULT_PARTITION__")])])])]),t._v(" "),v("li",[t._v("查询时，"),v("code",{pre:!0},[t._v("where")]),t._v("条件中如果以分区键为条件，就会自动使用分区查询")]),t._v(" "),v("li",[t._v("查询时，会根据元数据中的分区进行查询。元数据中没有的分区不会被查询\n"),v("ul",[v("li",[v("code",{pre:!0},[t._v("msck repair table xxx")]),t._v("根据HDFS中的实际文件来修复分区信息")])])]),t._v(" "),v("li",[t._v("添加分区："),v("code",{pre:!0},[t._v("alter table xxx add partition(k=v) partition(k=v) ... ;")]),t._v(" "),v("ul",[v("li",[t._v("注意没有逗号")])])]),t._v(" "),v("li",[t._v("删除分区："),v("code",{pre:!0},[t._v("alter table xxx drop partition(k=v), partition(k=v), ... ;")]),t._v(" "),v("ul",[v("li",[t._v("注意有逗号")])])]),t._v(" "),v("li",[t._v("查看分区："),v("code",{pre:!0},[t._v("show partitions <table name>;")])]),t._v(" "),v("li",[t._v("二级分区：有两个分区字段。嵌套分区\n"),v("ul",[v("li",[v("code",{pre:!0},[t._v("create table xxx (xxx) partitioned by (xxx xxx, xxx xxx);")])]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("load data inpath 'xxx' into table xxx partition(k=v, k=v);")])])])]),t._v(" "),v("li",[t._v("动态分区：自动根据数据字段把数据放到对应的分区\n"),v("ul",[v("li",[t._v("启用动态分区："),v("code",{pre:!0},[t._v("hive.exec.dynamic.partition=true")]),t._v("。默认开启")]),t._v(" "),v("li",[t._v("动态分区模式："),v("code",{pre:!0},[t._v("hive.exec.dynamic.partition.mode=nonstrict|strict")]),t._v(" "),v("ul",[v("li",[t._v("默认为strict，表示必须至少指定一个分区为静态分区")]),t._v(" "),v("li",[t._v("nonstrict表示所有分区都可以是动态分区")])])]),t._v(" "),v("li",[t._v("使用数据文件中已有的字段进行分区")]),t._v(" "),v("li",[t._v("注意：建表的时候，表的fields里面是没有目标字段的，目标字段仅出现在"),v("code",{pre:!0},[t._v("partitioned by")]),t._v("语句中")]),t._v(" "),v("li",[t._v("其他配置\n"),v("ul",[v("li",[v("code",{pre:!0},[t._v("hive.exec.max.dynamic.partitions=1000")]),t._v("所有节点上一共最多可以有多少动态分区。默认1000")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("hive.exec.max.dynamic.partitions.pernode=100")]),t._v("每个执行MR的节点最大可以创建多少动态分区。默认100。需要根据业务逻辑进行设置。比如分区键是一年中的天，那么分区数量就要设置大于366")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("hive.exec.max.created.files=100000")]),t._v("整个MR任务可以创建多少个HDFS文件。默认100000")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("hive.error.on.empty.partition=false")]),t._v("空分区被创建时是否抛出异常。默认false")])])])])])]),t._v(" "),v("h3",{attrs:{id:"分桶"}},[t._v("分桶")]),t._v(" "),v("ul",[v("li",[t._v("对于一个表或者一个分区，可以把数据拆分为文件，从而更细粒度地组织数据\n"),v("ul",[v("li",[t._v("分区针对数据路径，分桶针对数据文件")])])]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("create table xxx (xxx) clustered by (xxx) into x buckets")]),t._v(" "),v("ul",[v("li",[t._v("创建分桶表时，"),v("code",{pre:!0},[t._v("clustered by")]),t._v("中的属性必须是表的一个字段。而分区表的"),v("code",{pre:!0},[t._v("partitioned by")]),t._v("字段中的属性必须不属于表的字段")]),t._v(" "),v("li",[t._v("数据会哈希取模，然后分散在桶中")])])]),t._v(" "),v("li",[t._v("reduce的个数建议设置为-1，这样reducer的个数会等于桶的个数。或者设置大于桶的个数")]),t._v(" "),v("li",[t._v("抽样查询\n"),v("ul",[v("li",[v("code",{pre:!0},[t._v("select xxx from xxx tablesample (bucket x out of y on id);")]),t._v(" "),v("ul",[v("li",[t._v("根据id把数据集分为y等份，取第x份到第y份。x不大于y")])])]),t._v(" "),v("li",[t._v("适用于数据量非常大的场景")])])])]),t._v(" "),v("h3",{attrs:{id:"函数"}},[t._v("函数")]),t._v(" "),v("ul",[v("li",[t._v("内置函数\n"),v("ul",[v("li",[t._v("查看函数："),v("code",{pre:!0},[t._v("show functions")])]),t._v(" "),v("li",[t._v("解释函数："),v("code",{pre:!0},[t._v("desc function xxx")])]),t._v(" "),v("li",[t._v("详细解释函数："),v("code",{pre:!0},[t._v("desc function extended xxx")])]),t._v(" "),v("li",[t._v("常用内置函数\n"),v("ul",[v("li",[v("code",{pre:!0},[t._v("nvl(xxx, yyy)")]),t._v("如果xxx的值为NULL则替换为yyy\n"),v("ul",[v("li",[t._v("yyy可以是字段、常量、NULL")])])]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("case when then else end")]),t._v(" "),v("ul",[v("li",[t._v("例："),v("code",{pre:!0},[t._v("select sum(case sex when 'male' then 1 else 0 end) as maleCount from xxx;")])])])]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("if (condition, true value, false value)")]),t._v(" "),v("ul",[v("li",[t._v("例："),v("code",{pre:!0},[t._v("select sum(if(sex='male', 1, 0)) as maleCount")])])])]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("concat(xxx, yyy, ...)")]),t._v("拼接字符串")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("concat_ws(sep, xxx, yyy, ...)")]),t._v("拼接字符串，第一个参数为分隔符\n"),v("ul",[v("li",[t._v("支持接收array作为参数")])])]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("collect_set(xxx)")]),t._v("把字段进行去重后汇总为一个array（行转列，多行变一行）\n"),v("ul",[v("li",[t._v("可能和"),v("code",{pre:!0},[t._v("concat_ws")]),t._v("一起使用，比如"),v("code",{pre:!0},[t._v("concat_ws(',', collect_set(xxx))")])])])]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("explode(xxx)")]),t._v("炸裂。把复杂的array/map拆分为多行（列转行，一行变多行）")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("lateral view")]),t._v("侧写。如果要保留炸裂前的关系，则需要使用lateral view\n"),v("ul",[v("li",[t._v("如："),v("code",{pre:!0},[t._v("select xxx, zzz from ttt lateral ivew explode(yyy) kkk as zzz;")])])])]),t._v(" "),v("li",[t._v("窗口函数"),v("code",{pre:!0},[t._v("over")]),t._v(" "),v("ul",[v("li",[v("code",{pre:!0},[t._v("over()")]),t._v("根据"),v("code",{pre:!0},[t._v("group by")]),t._v("设置窗口，计算每个"),v("code",{pre:!0},[t._v("group by")]),t._v("得到的分组的数据")]),t._v(" "),v("li",[t._v("比如："),v("code",{pre:!0},[t._v("select name, count(*) over () from xxx group by name;")]),t._v("，其中计算"),v("code",{pre:!0},[t._v("count(*)")]),t._v("的时候会应用一个窗口，窗口大小为group的大小")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("over (partition by xxx, yyy, ...)")]),t._v("会根据某个字段设置窗口")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("over (partition by xxx order by xxx rows between unbounded preceding and current row)")]),t._v("指定窗口范围\n"),v("ul",[v("li",[v("code",{pre:!0},[t._v("current row")]),t._v("当前行")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("n preceding")]),t._v("前n行")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("n following")]),t._v("后n行")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("unbounded")]),t._v("起点\n"),v("ul",[v("li",[v("code",{pre:!0},[t._v("unbounded preceding")]),t._v("从起点")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("unbounded following")]),t._v("到终点")])])]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("lag(col, n, default)")]),t._v("往前第n行")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("lead(col, n, default)")]),t._v("往后第n行")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("ntile(n)")])])])])])]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("rank")]),t._v("排名。出现重复时，总数不变\n"),v("ul",[v("li",[t._v("比如："),v("code",{pre:!0},[t._v("1,2,2,4")])])])]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("dense_rank")]),t._v("排名。出现重复时，总数减少\n"),v("ul",[v("li",[t._v("比如："),v("code",{pre:!0},[t._v("1,2,2,3")])])])]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("row_number")]),t._v("根据顺序排名，不会重复，但是相同排名可能乱序\n"),v("ul",[v("li",[t._v("比如："),v("code",{pre:!0},[t._v("1,2,3,4")])])])])])])])]),t._v(" "),v("li",[t._v("自定义函数\n"),v("ul",[v("li",[t._v("分类：\n"),v("ul",[v("li",[t._v("UDF(User Defined Function)\n"),v("ul",[v("li",[t._v("一行输入一行输出")]),t._v(" "),v("li",[t._v("比如\n"),v("ul",[v("li",[t._v("upper")])])])])]),t._v(" "),v("li",[t._v("UDAF(User Defined Aggregate Function)\n"),v("ul",[v("li",[t._v("多行输入一行输出")]),t._v(" "),v("li",[t._v("比如\n"),v("ul",[v("li",[t._v("max")]),t._v(" "),v("li",[t._v("min")]),t._v(" "),v("li",[t._v("count")])])])])]),t._v(" "),v("li",[t._v("UDTF(User Defined Table Function)\n"),v("ul",[v("li",[t._v("一行输入多行输出")]),t._v(" "),v("li",[t._v("比如\n"),v("ul",[v("li",[t._v("explode")])])])])])])]),t._v(" "),v("li",[t._v("需要编程实现，集成Hive提供的Java类，实现抽象方法即可")])])])]),t._v(" "),v("h3",{attrs:{id:"压缩和存储"}},[t._v("压缩和存储")]),t._v(" "),v("ul",[v("li",[t._v("执行过程中使用MapReduce的压缩。在MR里面配置。略")]),t._v(" "),v("li",[t._v("最终输出结果可以配置压缩\n"),v("ul",[v("li",[v("code",{pre:!0},[t._v("hive.exec.compress.output=true")]),t._v("。默认值是false，以便查看输出")])])])]),t._v(" "),v("p",[t._v("配置最终压缩过程（Hive客户端）：")]),t._v(" "),v("ol",[v("li",[t._v("启动hive压缩："),v("code",{pre:!0},[t._v("set hive.exec.compress.output=true;")])]),t._v(" "),v("li",[t._v("启动MR最终输出压缩："),v("code",{pre:!0},[t._v("set mapreduce.output.fileoutputformat.compress=true;")])]),t._v(" "),v("li",[t._v("设置MR输出压缩格式："),v("code",{pre:!0},[t._v("set mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.SnappyCodec;")])]),t._v(" "),v("li",[t._v("设置MR压缩为块压缩："),v("code",{pre:!0},[t._v("set mapreduce.output.fileoutputformat.compress.type=BLOCK;")])])]),t._v(" "),v("h3",{attrs:{id:"文件存储格式"}},[t._v("文件存储格式")]),t._v(" "),v("h4",{attrs:{id:"行式存储和列式存储"}},[t._v("行式存储和列式存储")]),t._v(" "),v("p",[t._v("假设有一个表格：")]),t._v(" "),v("table",[v("thead",[v("tr",[v("th",[t._v("name")]),t._v(" "),v("th",[t._v("age")])])]),t._v(" "),v("tbody",[v("tr",[v("td",[t._v("aaa")]),t._v(" "),v("td",[t._v("1")])]),t._v(" "),v("tr",[v("td",[t._v("bbb")]),t._v(" "),v("td",[t._v("2")])]),t._v(" "),v("tr",[v("td",[t._v("ccc")]),t._v(" "),v("td",[t._v("3")])])])]),t._v(" "),v("ul",[v("li",[t._v("基于行存储："),v("code",{pre:!0},[t._v("aaa,1,bbb,2,ccc,3")])]),t._v(" "),v("li",[t._v("基于列存储："),v("code",{pre:!0},[t._v("aaa,bbb,ccc,1,2,3")])])]),t._v(" "),v("p",[t._v("由于类SQL通常以列（字段）进行查询，所以生产环境通常使用列存储作为存储格式，性能更高")]),t._v(" "),v("h4",{attrs:{id:"文件格式"}},[t._v("文件格式")]),t._v(" "),v("ul",[v("li",[v("code",{pre:!0},[t._v("TEXTFILE")]),t._v("（默认）\n"),v("ul",[v("li",[t._v("文本")]),t._v(" "),v("li",[t._v("基于行存储")])])]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("SEQUENCEFILE")]),t._v(" "),v("ul",[v("li",[t._v("二进制")]),t._v(" "),v("li",[t._v("基于行存储")])])]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("ORC")]),t._v(" "),v("ul",[v("li",[t._v("Optimized Row Columnar")]),t._v(" "),v("li",[t._v("由Hive 0.11引入的存储格式")]),t._v(" "),v("li",[t._v("基于列存储")]),t._v(" "),v("li",[t._v("先把整个数据按行分段(stripe)，然后对端进行列式存储")]),t._v(" "),v("li",[t._v("每个stripe有自己的索引信息，以便加速查询")])])]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("PARQUET")]),t._v(" "),v("ul",[v("li",[t._v("基于列存储，二进制，文件包含数据和元数据，可以自解析")]),t._v(" "),v("li",[t._v("行组(Row Group)\n"),v("ul",[v("li",[t._v("类似于ORC的Stripe，把整个数据分成若干行组，每个行组包含若干行。一个HDFS文件中至少保存一个行组")])])]),t._v(" "),v("li",[t._v("列块(Column Chunk)\n"),v("ul",[v("li",[t._v("单个行组中的每一列都保存在一个列块中")]),t._v(" "),v("li",[t._v("行组的所有列，连续地存储在这个行组文件中")]),t._v(" "),v("li",[t._v("一个列块中的所有值的类型相同")]),t._v(" "),v("li",[t._v("不同的列块可以使用不同压缩算法")])])]),t._v(" "),v("li",[t._v("页(Page)：每个列块分为若干页\n"),v("ul",[v("li",[t._v("页是Parquet最小编码单位")]),t._v(" "),v("li",[t._v("同一个列块的不同页可能使用不同编码方式")])])])])])]),t._v(" "),v("p",[t._v("使用场景：")]),t._v(" "),v("ul",[v("li",[t._v("Hive环境下，不同存储格式的查询效率差不多，ORC存储效率高，所以通常使用ORC")]),t._v(" "),v("li",[t._v("Spark环境默认使用Parquet格式文件，对Parquet格式有优化，性能更高")])]),t._v(" "),v("p",[t._v("不同的存储格式可以和压缩方案结合，实现更高的性能")]),t._v(" "),v("h3",{attrs:{id:"优化"}},[t._v("优化")]),t._v(" "),v("ul",[v("li",[t._v("执行计划：查看优化后的查询语句\n"),v("ul",[v("li",[t._v("语法："),v("code",{pre:!0},[t._v("explain [extended | dependency | authorization] xxx")])])])]),t._v(" "),v("li",[t._v("Fetch抓取\n"),v("ul",[v("li",[t._v("某些查询可能不走MR任务比走MR任务更快")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("hive.fetch.task.conversion=more")]),t._v(" "),v("ul",[v("li",[t._v("老版本是"),v("code",{pre:!0},[t._v("minimal")])]),t._v(" "),v("li",[t._v("设置为"),v("code",{pre:!0},[t._v("more")]),t._v("后，全局查找、字段查找、limit查找等任务不走MR")])])])])]),t._v(" "),v("li",[t._v("本地模式\n"),v("ul",[v("li",[t._v("数据量小的时候，在单台机器上面执行所有任务，可能更快（因为不需要网络IO）")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("hive.exec.mode.local.auto=true")]),t._v("启动自动本地模式")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("hive.exec.mode.local.auto.inputbytes.max=134217728")]),t._v("启动本地模式的最大数据量，默认128M")]),t._v(" "),v("li",[v("code",{pre:!0},[t._v("hive.exec.mode.local.auto.input.files.max=4")]),t._v("启动本地模式的最大文件数。默认4.")]),t._v(" "),v("li",[t._v("如果单个节点性能优秀，那么增加上述上限可以提升任务执行效率")])])]),t._v(" "),v("li",[t._v("表的优化，略，详见视频（偷懒）")])])])}]};t.exports={attributes:{title:"Big Data(Part 3)",description:"Hive",tags:["Hadoop"]},vue:{render:v.render,staticRenderFns:v.staticRenderFns,component:{data:function(){return{templateRender:null}},render:function(t){return this.templateRender?this.templateRender():t("div","Rendering")},created:function(){this.templateRender=v.render,this.$options.staticRenderFns=v.staticRenderFns}}}}}}]);