---
title: Big Data(Part 5)
description: HBase
tags:
  - Hadoop
---

## 前言

本文是观看[此视频](https://www.bilibili.com/video/BV1Y4411B7jy)时的笔记

## HBase

### 概述

- 分布式、可扩展、支持海量数据的NoSQL数据库
- 基于谷歌的Big Table论文
- 数据量越大，优势越明显
- 读比写慢
- 作为一个存储引擎，可以和已有的分析引擎/计算引擎进行集成，比如MapReduce/Hive/Spark

### 数据模型

- 逻辑上
  - 和关系型数据库很像，有行有列，而且比较稀疏
  - namespace
    - 类似于mysql中的database。用来隔离数据
    - 两个自带的命名空间
      - `hbase`保存HBase内置的表
      - `default`默认命名空间
    - 表的名字是`<namespace>:<table>`
  - 表。类似于mysql中的table
    - 一个表会根据row key的字典序被横向切分为多个region
  - region（切片）
    - 表的横向切片，每个region包含一个row key的范围
  - row key（行键）
    - 是每行数据的唯一ID
    - **字典序**
  - column family（列族）
    - 包含多个列，也可以一个列。是表的纵向切片
    - 一个表的不同列划分到不同的列族
    - 创建表的时候只需要指明列族即可，不需要声明具体的列。所以写数据的时候，列可以动态指定
    - 不同的列族在不同的文件夹下存储
    - 一个列族被横向拆分为多个store，分布在不同region上
    - 官方建议生产环境只有一个列族，避免多个列族数据稀疏不同，导致在flush的时候产生过多小文件
  - cell（单元格）
    - 由row key, column family, column qualifier, timestamp唯一确定的单元
    - 无类型，物理上以字节数组的形式存储
  - store
    - 一个二维表会被根据列族和region进行划分成若干个store，存储在不同HDFS文件中
    - store在HDFS中表现为文件夹，里面是每次flush下来的文件或者合并之后的文件
- 底层/物理上
  - 是k/v存储，类似于multi-dimensional map
  - 每一行包含
    - `row key`行键
    - `column family`列族
    - `column qualifier`列名
    - `timestamp`时间戳
    - `type`事件类型
    - `value`值
  - 因为**时间戳、事件类型**的存在，可以像时序数据库一样持续append数据，最后汇总得到结果
  - 因为存在时间戳，可以查询某个时间/时间段的数据
  - 刚写的数据先保存在内存中，然后定时刷到HDFS的文件中
  - 可以给列族设置版本数量上限，使其能够保存多个版本的数据
  - 由于需要根据时间戳合并数据，所以读比写慢
  - HDFS中的目录结构：`/HBase/data/<namespace>/<table>/<region>/<column family>/<store files>`

### 架构

- Zookeeper集群
  - 负责管理HBase集群
  - DDL之外的语句，可以通过ZK直接发往Region Server而不经过Master节点
- Master节点
  - 负责表级别的管理(DDL)
  - 支持的操作
    - 对表进行create/delete/alter
    - 监控每个region server
    - 分配region到region server
  - 如果master挂了，只是DDL无法执行。操作数据的DML仍然可以对region server执行
  - 自带高可用，基于Zookeeper实现
- Region Server
  - 管理一个HLog和多个region
  - HLog是WAL(Write Ahead Log)预写入日志，类似于MySQL redo log。数据写入内存而没有落盘时，先在HLog中记录，防止断电丢失
  - 负责region级别的操作，或者说对数据的操作(DML)
  - 支持的操作
    - 对data执行get/put/delete
    - 对region执行split/compact
  - region包含多个store
  - store管理多个store file(HFile格式，内部是kv)并管理一个mem store(内存存储，用来保存新数据)
    - 内存数据在一段时间后会被刷到HFile
    - HFile在HDFS上

### 流程

#### 写数据和Flush

1. 客户端请求ZK，查询`/hbase/meta-region-server`，得到`hbase:meta`表所在的Region Server
2. 客户端请求Region Server，查询`get 'hbase:meta', '<table>,<region info>', 'info:server'`，得到要写的表所在的Region Server，并在客户端缓存
   1. `hbase:meta`表中会为每个region创建一条记录。这样客户端就能直接查到该往哪个region server写数据
3. 客户端向目标表所在的Region Server发出PUT请求
   1. 数据先被写到WAL（但先不同步到HDFS）
   2. 然后被写入内存MemStore
   3. 试图同步WAL到HDFS。如果失败，回滚MemStore
4. Region Server根据时间和数据量的条件，把MemStore中的数据写到HDFS中的HFile中(Store File)
   1. `hbase.regionserver.global.memstore.size`可以配置region server的内存被占用多少的时候会停止客户端读写来进行flush
      1. 默认值为0.4（即内存的40%）
      2. flush的时候会阻塞客户端的读写
   2. `hbase.regionserver.global.memstore.size.lower.limit`可以配置region server的内存被占用多少的时候开始flush
      1. 默认值为0.95，即`hbase.regionserver.global.memstore.size`的95%
      2. 假设内存10G，在被占用`10G * 0.4 * 0.95 = 3.8G`的时候开始flush所有region的memstore，被占用`10G * 0.4 = 4G`的时候停止客户端读写
   3. `hbase.regionserver.optionalcacheflushinterval`如果超过了这个时间还没有flush，那就启动flush
      1. 单位毫秒，默认3600000，即1小时
      2. 从最后一次编辑事件开始算起
   4. `hbase.hregion.memstore.flush.size`region级别的flush阈值
      1. 默认134217728，即128MiB
      2. 仅flush一个region
   5. 每次flush会为region生成一个文件，等待compact进行合并。而不是在flush阶段就直接进行合并

> 老版本的HBase担心meta表也会因为太大而切分，所以又设置了一个`-root-`表用来保存meta表的信息，并把root表保存在ZK中。后来实际生产环境发现meta表通常不会膨胀到需要切分的程度，并设置meta表无法被切分

#### 读数据

1. 客户端请求ZK，查询`/hbase/meta-region-server`，得到`hbase:meta`表所在的Region Server
2. 客户端请求Region Server，查询`get 'hbase:meta', '<table>,<region info>', 'info:server'`，得到要写的表所在的Region Server，并在客户端缓存
3. 客户端向目标表所在的Region Server发出GET请求
   1. store的StoreFile会在Region Server的磁盘上保留一个block cache
      1. 基于LRU（最近最少访问，使用Linked Hash Map实现）进行缓存过期
   2. 根据时间戳进行合并block cache和memcache里面的数据得到结果
   3. 所以HBase每次GET都需要查磁盘上的block cache（如果磁盘没有，甚至还要查HDFS），导致读取比较慢

#### Compact

定期合并小文件。Compact分两种：

- minor
  - 合并小的、相邻的HFile文件为一个较大的HFile，**不会** 清理过期数据和删除的数据
- major
  - 把一个Store下面所有的HFile合并为一个大HFile，并清理过期/删除的数据
  - 通常用major合并多一些
  - `hbase.hregion.majorcompaction`配置合并时间。默认604800000（7天）
    - major compaction很耗资源，生产环境建议关闭，设置为0，然后在空闲时间手动触发
  - `hbase.hregion.majorcompaction.jitter`合并时间抖动比例。默认0.50，即50%的抖动比例
  - `hbase.hstore.compactionThreshold`一个store里面允许的文件个数。达到这个个数就会触发合并（但是延迟比较高）。默认3

#### 清理数据

- flush的时候，清理memstore中被新版本覆盖的数据，然后清空memstore
  - flush的时候，如果memstore中的数据被标记删除，则仍然会把删除标记给flush到HDFS，因为可能需要删除HDFS上的数据
- major compact的时候，清理被删除（有删除标记）或者过期的数据，包括HFile里面被新版本覆盖的数据

#### 数据分片

- 0.94版本之前
  - 一个region的某个store的所有StoreFile总大小超过`hbase.hregion.max.filesize`的时候拆分。默认10G
- 0.94之后
  - 一个region的某个store的所有StoreFile总大小超过`Min(R^2 * hbase.hregion.memstore.flush.size, hbase.hregion.max.filesize)`的时候拆分。R为当前Table的Region数量
  - Table只有一个region的时候，默认值为128M
  - 切分的时候，按照Row key取中间值进行切分。
  - 可能会存在数据倾斜
    - 一个分区64M，一个分区10G
    - 解决方案：建表的时候预分区

### 常见命令

- `hbash shell`进入交互式命令行
  - `help`查看命令帮助
    - `help <cmd>`查看命令帮助
    - `help <cmd-group>`查看一组命令的帮助
      - `help general`查看常见命令
      - `help ddl`查看DDL命令
      - `help dml`查看DML命令
      - `help namespace`查看名称空间相关命令
  - `list`列出表
  - `describe <table>`查看表详细信息
  - `create '<table>','<column>',...,'<column>'`创建表
    - `create 'student','info'`在默认名称空间建表
    - `create 'xxx:student','info'`在`xxx`名称空间建表
    - 一个表至少有一个列
  - `alter '<table>',{<key>=>'<value>',...,<key>=>'<value>'}`修改列的属性
    - 会修改所有region
    - `alter 'student', {NAME=>'info', VERSIONS=>2}`
      - 修改`student`表的`info`列族，使其能够保存2个版本的数据
  - `disable '<table>'`禁用表。禁用之后才能删除表
  - `drop '<table>'`删除表
  - `list/create/drop_namespace`执行namespace级别的操作
  - `put '<table>', '<row key>', '<column>', '<value>'`写数据/改数据
    - `put 'student', '1001', 'info:name', 'xxx'`
      - 向`student`表写数据
      - row key为`1001`
      - 数据写在`info`列的`name`维度
      - 值为`xxx`
  - `scan`扫描全表
  - `get`查询数据
  - `delete`删除数据的某个列
  - `truncate`清空表
  - `deleteall`删除一个row key对应的数据（删除一行）
  - `flush`落盘（到HDFS）
  - `compact`合并文件
  - `major_compact`执行major合并

## 优化

- 预分区
- row key的设计
  - 随机数
  - 哈希值
  - 散列值
  - 字符串反转
  - 字符串拼接

详见视频


