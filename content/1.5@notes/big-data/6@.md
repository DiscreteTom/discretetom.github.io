---
title: Big Data(Part 6)
description: Flume
---

## 前言

本文是观看[此视频](https://www.bilibili.com/video/BV184411B7kU)时的笔记

## Flume

### 概述

- Flume是Cloudera提供的高可用、高可靠、分布式的海量**日志**采集、聚合、传输系统
  - Flume默认是一个单机的程序。通过Avro可以构建集群/分布式
- 基于流式架构，灵活简单
- 可以监控文件夹/磁盘上的文件变化，也可以监听网络端口
- 数据目标通常是HDFS和Kafka
- 监控：Ganglia（已过时）

### 概念

- Agent
  - 一个JVM进程，采集数据，包括Source/Channel/Sink三大组件
  - 以事件(Event)的形式把数据从source送到sink
- Source
  - 传输数据/过滤数据
  - 可以自定义Source
  - 常见source包括Avro(RPC框架，用来实现多个Flume级联通信)/Thrift/Exec(监控命令行输出)/SpoolingDirectory/Taildir(监控多个目录)/Kafka/NetCat/Syslog
- Channel
  - 常见Channel包括：Memory/JDBC/Kafka/File
  - 支持自定义
  - Memory Channel速度快，但是数据可能丢。File Channel速度比内存慢，但是数据安全，且量大
- Sink
  - 常见Sink包括HDFS/Hive/Logger(输出到控制台)/Avro/Thrift/Kafka/HBase/FIleRole/ElasticSearch
  - 支持自定义
- Event
  - 数据基本传输单元
  - 由header和body组成
  - header是k/v数据。body是二进制数据

### 配置文件

```conf
# file: netcat-flume-logger.conf

# configure agent
a1.sources = r1 r2 r3
a1.sinks = k1
a1.channels = c1

# configure source
a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 4444

# configure sink
a1.sinks.k1.type = logger

# configure channel to buffer events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000 # number of events
a1.channels.c1.transactionCapacity = 100 # number of events to be transmitted

# bind source and sink to channel
a1.sources.r1.channels = c1 # one source can send to many channels
a1.sinks.k1.channel = c1 # one sinks can only receive from one channel
```

### 命令

- `bin/flume-ng agent --conf conf/ --conf-file job/netcat-flume-logger.conf --name a1 -Dflume.root.logger==INFO,console`
  - 使用`nc localhost 44444`写入数据
  - `agent`表示启动agent，使用`--name a1`指定agent名字，全局（多进程）唯一
  - `--conf conf/ --conf-file xxx`指定配置文件的路径和文件名
  - 可以使用`source-flume-sink.conf`作为任务配置文件的文件名，比如`netcat-flume-logger.conf`
  - `-Dflume.root.logger==INFO,console`定义logger sink的细节。比如数据详细程度为INFO，并输出到控制台

### 示例

- 监控本地文件尾部更新
  - 使用`Exec`作为source，命令为`tail -f xxx`或者`tail -F xxx`。使用`-F`的tail命令会自动重试
    - 无法保证数据不丢失（比如agent挂掉）
- 监听文件夹，有新文件时上传
  - 使用`Spooldir`作为source
    - 可以保证数据不丢失，支持断点续传，但是延迟比较高，非实时
- 断点续传文件
  - 使用`Taildir`作为source
    - 支持断点续传，保证数据不丢失，而且是实时监控
    - 支持监控多个文件夹中的多个文件

### 事务

- 保证数据一致性
- source-channel之间存在事务(put)，channel-sink之间也存在事务(take)
- put事务流程
  - doPut - 把数据写入临时缓冲区putList
  - doCommit - 检查channel内存队列是否足够合并
  - doRollback - 如果channel的内存空间不足，则回滚putList
- take事务流程
  - doTake - 从channel获取数据到临时缓冲区takeList
  - doCommit - 如果成功发送数据，则清除takeList
  - doRollback - 如果数据发送失败，把takeList的数据回滚到channel

### Agent内部工作流

1. 从Source获取事件
2. 事件被发送到Channel Processor
3. Channel Processor把事件传递给拦截器(Interceptor)链，用来增强数据
4. Channel Processor调用Channel Selector，选择事件对应的channel
   1. Replicating Channel Selector(default)，把事件发往所有channel
   2. Multiplexing Channel Selector，把事件发往指定的channel
5. Channel Processor把事件写入Channel
6. Sink Processor从Channel获取事件
   1. DefaultSinkProcessor
   2. LoadBalancingSinkProcessor
      1. 轮询
      2. 随机
      3. ...
      4. 自定义
   3. FailoverSinkProcessor
7. Sink Processor把事件发往sink

Processor都可以自定义。拦截器也可以自定义

### 拓扑结构和集群

- 使用Avro实现级联Flume，实现简单串联
- 使用一个source对应多个channel，每个channel对应一个sink的方式，实现事件复制、多路复用
- 使用SinkProcessor实现负载均衡和故障转移
- 多个Avro Sink指向同一个Avro Source实现事件聚合，也可以多个source指向一个sink

