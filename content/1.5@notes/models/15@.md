---
title: 信息论
description: 信息熵、霍夫曼编码、帧间压缩、互信息、冗余度
---

## 三条重要公式

张首晟：对于人类文明来讲，有三条最重要的公式

- 爱因斯坦质能方程，描述了物质和能量的关系
  - 物质和能量同源，可以相互转换
- 香浓的信息熵公式，描述信息如何量化
- 海森堡不确定性原理，描述了科学的边界
  - 主观行为会影响客观结果
  - 我们观察到的是客观世界和主观想象之间的结合体

能量是守恒的，但是信息是可以复制的。分享知识是一件可以为这个世界创造纯粹增量的事情

## 信息熵

- 概率越小，信息熵越大
- 可能性越多，信息熵越大
- 每个事件的概率都相同时，总体信息熵最大
- 如果有一个事件的出现概率很大，整体信息熵就会大大降低
- 信息量：把信息熵消除掉所需要的信息的量，单位为比特

启发：

- 模棱两可的态度是没有信息量的
- 不做选择，随波逐流，平均分配注意力，会增加整个系统的无序性

## 霍夫曼编码

- 理论上最高效的编码信息的方式
- 启发：把最多的资源安排在最常用的场景
- 结合奥卡姆剃刀，得到结论：大刀阔斧做减法，围绕关键领域饱和配置资源
  - 因为吃饭很高频，减少吃饭时间，就可以获得大量自由时间
  - 因为使用电脑/手机非常高频，所以买配置比较高的产品
  - 看理论书的时候慢点看，看其他书的时候快点看

## 帧间压缩算法

- 关注信息增量而不是信息存量来提升效率
- 关注变化，忽略重复，可以大幅提升效率
  - 比如看书的时候如果有很多已知的知识，可以快速略过
- 起步的时候把基本功练扎实，以后就可以通过增量学习快速前进

## 互信息

- Mutual Information
- 两个事情之间的互信息越大，说明相关性越强
  - 注意：相关不一定有因果
- 通过互信息，我们可以指导一个事情可以给另一个事情消除多大的不确定性，减少多少信息熵
  - 两个事件的相关性是可以严格算出的
  - 只要互信息比较高，就可以视为有相关性，而不需要寻找因果性
  - 人类善于寻找因果，而不善于分析数据。但是世界上很多事情都是相关的而不是因果的
  - 比如基于历史行为的个性化推荐，就是挖掘数据，然后可能可以找到因果
- 信息等价：知道信息 A 的时候变相知道了信息 B
  - 比如：废话文学
  - 互信息很高
  - 沟通的时候如果一直说类似的废话，效率很低

## 冗余度

- 资源的重复度
- 虽然使用废话效率低，但是冗余度高，提供更强的可靠性
- 冗余度太低，接收信息的难度就会变高（对于人类来说）
- 小说、故事提供了更多的冗余度，所以人类喜欢听。论文的冗余度就很低
- 现代人更倾向于使用简写，比如 yyds，就是因为冗余度足够高，所以可以使用这种信息量更少的方法进行表示
- 如何去除冗余信息？画分析框架
  - 不一定是脑图，毕竟脑图只是树，不是图
  - 一个参考流程：
    - 先抽象出实体，然后建立联系，并移除等价的实体，然后套用已有的知识试图理解和矫正
